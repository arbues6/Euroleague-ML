{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Predicting Lineup Performance\n",
    "\n",
    "This Notebook attempts to predict the performance of a hypothetical lineup in terms of any advanced statistic. In order to do so, a regression model will be trained from scratch by using simple linear regression, which is included in the group of supervised methods. In this case, there was no need to label data manually; instead, all possible on-court combinations have been obtained from play-by-play data together with their corresponding statistics (both on offense and defense). Therefore, by modelling each player with features and by building a unique feature vector for each combination, a linear model can be trained whilst using the associated stats as ground-truth. Please note that the given example provides a simple baseline, but many other rellevant factors haven't been taken into account yet. However, if you are interested in a Deep Learning Keras/Pytorch-based model with a FCL-architecture, let me know! \n",
    "\n",
    "Sidenote: I don't really know why, but I've always been more comfortable when using .npy files instead of .csv's; if you prefer the latter, feel free to adapt the code with these files: https://drive.google.com/drive/folders/1GIeoWWMbZO02idPNlVVQLJWLWbtespiX?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "As always, we start loading our data and inspecting what might we find in it. \n",
    "In this scenario, and using a fixed number of players (2-3-4), we are gonna load two datasets: \n",
    "1. All possible combinations given the desired number of players, including players and team names, as well as basic offensive and defensive stats. \n",
    "2. Feature vectors that define each player with 10 characteristics. These vectors are the ones detailed in the previous Notebook of Classification; as mentioned, these features include (1) 3-point Proficiency, (2) Offensive Load, (3) True Shooting percentage, (4) FTA/FGA, (5) Offensive and (6) Defensive Rebouding Percentage, (7) Assist Ratio, (8) Turnover Ratio, (9) Steal Ratio, and (10) (2FG/2FGA) of the opponent team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare number of players and features to be used \n",
    "nPlayers = 4 # Could be changed to 2 - 3 - 4 - 5\n",
    "nFeats = 10\n",
    "# Decide minimum number of possessions on court of each combination of players\n",
    "if nPlayers == 2:\n",
    "    minPoss = 500\n",
    "elif nPlayers == 3:\n",
    "    minPoss = 250\n",
    "elif nPlayers == 4:\n",
    "    minPoss = 200\n",
    "elif nPlayers == 5:\n",
    "    minPoss = 100\n",
    "\n",
    "# Load matrices\n",
    "sFolder = '/Users/arbues/Documents/UCAM/Euroleague-Notebooks/Data/'\n",
    "# Lineup combinations of nPlayers\n",
    "if nPlayers!=4:\n",
    "    allLineups = np.load(sFolder + \"Lineup-Combos/PermPlayers\" + str(nPlayers) + \".npy\", allow_pickle=True)\n",
    "else:\n",
    "    allLineups1 = np.load(sFolder + \"Lineup-Combos/PermPlayers\" + str(nPlayers) + \"a.npy\", allow_pickle=True)\n",
    "    allLineups2 = np.load(sFolder + \"Lineup-Combos/PermPlayers\" + str(nPlayers) + \"b.npy\", allow_pickle=True)\n",
    "    allLineups = np.concatenate([allLineups1,allLineups2])\n",
    "# Corresponding teams\n",
    "allTeams = np.load(sFolder + \"Lineup-Combos/PermTeams\" + str(nPlayers) + \".npy\", allow_pickle=True)\n",
    "# Corresponding offensive stats\n",
    "# Input vec: [0] 2FGM, [1] 2FGA, [2] 3FGM, [3] 3FGA, [4] FTM, [5] FTA, [6] DReb, [7] OReb, [8] Ast, [9] 'null', [10] TOV\n",
    "basicStatsOf = np.load(sFolder + \"Lineup-Combos/basicStatsOf\" + str(nPlayers) + \".npy\", allow_pickle=True)\n",
    "# Corresponding defensive stats\n",
    "basicStatsDef = np.load(sFolder + \"Lineup-Combos/basicStatsDef\" + str(nPlayers) + \".npy\", allow_pickle=True)\n",
    "# Feature vectors of all players (except 2019-2020)\n",
    "featVecsInd = np.load(sFolder + \"Lineup-Combos/FeatVecsIndN.npy\", allow_pickle=True)\n",
    "# Names of each feature vector\n",
    "matNames = list(np.load(sFolder + \"Lineup-Combos/FeatVecsIndNames.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect once again what type of data are we dealing with here (collective lineups + individual feature vectors): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JACKSON, MARC 2007 OLY\n",
      "Players: ['GRANGER, JAYSON' 'HUERTAS, MARCELINHO' 'MCRAE, JORDAN'\n",
      " 'SHENGELIA, TORNIKE']  | Team: BAS\n",
      "Offensive Stats: [[0. 1. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 2. 1. 0.]\n",
      " [6. 6. 4. ... 5. 4. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 2. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Defensive Stats: [[ 1.  1.  0. ...  1.  1.  0.]\n",
      " [ 1.  1.  1. ...  1.  2.  0.]\n",
      " [ 6. 10.  3. ...  3.  5.  0.]\n",
      " ...\n",
      " [ 0.  1.  0. ...  2.  2.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "Feature Vector of: GRANGER, JAYSON 2017 BAS: [0.38732658 0.44316652 0.5433914  0.15811966 0.01574803 0.26395939\n",
      " 0.25972703 0.04558301 0.01028807 0.47154472]\n",
      "Feature Vector of: HUERTAS, MARCELINHO 2010 BAS: [0.39960751 0.59725617 0.56441327 0.32846715 0.04234528 0.27027027\n",
      " 0.35289747 0.06729081 0.01393612 0.45652174]\n",
      "Feature Vector of: HUERTAS, MARCELINHO 2017 BAS: [0.4363905  0.39564912 0.53566762 0.23021583 0.0228013  0.14556962\n",
      " 0.26046884 0.04635219 0.00382117 0.40625   ]\n",
      "Feature Vector of: HUERTAS, MARCELINHO 2018 BAS: [0.41978234 0.42449509 0.59325946 0.20100503 0.03614458 0.17085427\n",
      " 0.27797203 0.05992225 0.01538246 0.52447552]\n",
      "Feature Vector of: SHENGELIA, TORNIKE 2014 BAS: [0.21038185 0.4500516  0.51079414 0.48538012 0.12091503 0.47222222\n",
      " 0.06908198 0.04230349 0.01719304 0.44927536]\n",
      "Feature Vector of: SHENGELIA, TORNIKE 2016 BAS: [0.44001259 0.33040491 0.59625213 0.44067797 0.1009772  0.47260274\n",
      " 0.08092202 0.04123039 0.0168218  0.50649351]\n",
      "Feature Vector of: SHENGELIA, TORNIKE 2017 BAS: [0.29818411 0.3428418  0.62471668 0.45578231 0.10927835 0.59349593\n",
      " 0.10488235 0.03101963 0.01428637 0.61693548]\n",
      "Feature Vector of: SHENGELIA, TORNIKE 2018 BAS: [0.36315946 0.33278466 0.5495565  0.6196319  0.05993691 0.50393701\n",
      " 0.08732931 0.03169734 0.02308125 0.52592593]\n"
     ]
    }
   ],
   "source": [
    "print(matNames[0])\n",
    "\n",
    "iPosAux = 0\n",
    "print('Players: ' + str(allLineups[iPosAux]), ' | Team: ' + str(allTeams[iPosAux]))\n",
    "print('Offensive Stats: ' + str(basicStatsOf))\n",
    "print('Defensive Stats: ' + str(basicStatsDef))\n",
    "for iP in range(0, nPlayers):\n",
    "    for iYear in range(2007, 2019):\n",
    "        namePlayer = allLineups[iPosAux][iP] + ' ' + str(iYear) + ' ' + str(allTeams[iPosAux])\n",
    "        try:\n",
    "            print('Feature Vector of: ' + namePlayer + ': ' + str(featVecsInd[matNames.index(namePlayer)]))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you all know, using basic stats might fall short in several scenarios, so the above-displayed digits should be converted into some kind of advanced metrics. In the following function, the computation of some gold-standard state-of-the-art metrics are provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch from basic to advanced stats\n",
    "def basic2advancedStats(matrix,lineups,matrixAux,minPoss,teams):\n",
    "    # Possessions\n",
    "    possessions = 0.96*(matrix[:,0]+matrix[:,1]+matrix[:,2]+matrix[:,3]+matrix[:,10]+0.44*(matrix[:,4]+matrix[:,5])-matrix[:,7])\n",
    "    # Filter by minimum possessions\n",
    "    possessionsVal = possessions>minPoss\n",
    "    possessions = possessions[possessionsVal]\n",
    "    lineups = lineups[possessionsVal]\n",
    "    teams = teams[possessionsVal]\n",
    "    matrix = matrix[possessionsVal]\n",
    "    matrixAux = matrixAux[possessionsVal]\n",
    "    # OER-DER\n",
    "    OER = (100*(2*matrix[:,0]+3*matrix[:,2]+matrix[:,4]))/possessions\n",
    "    DER = (100*(2*matrixAux[:,0]+3*matrixAux[:,2]+matrixAux[:,4]))/possessions\n",
    "    # Assist Ratio (you can switch from percentage of assisted shots or ratio per possession)\n",
    "    # ASTr = (matrix[:,8]*100)/(matrix[:,0]+matrix[:,1]+matrix[:,2]+matrix[:,3]+matrix[:,10]+0.44*(matrix[:,4]+matrix[:,5])+matrix[:,8])\n",
    "    ASTr = (matrix[:,8]*100)/(matrix[:,0]+matrix[:,2]+0.44*(matrix[:,4]))\n",
    "    # Offensive Rebounding Ratio\n",
    "    OReb = (matrix[:,7]*100)/(matrix[:,7]+matrixAux[:,6])\n",
    "    # Defensive Rebounding Ratio\n",
    "    DReb = (matrix[:,6]*100)/(matrix[:,6]+matrixAux[:,7])\n",
    "    # Turnover Ratio\n",
    "    TOV = (matrix[:,10]*100)/(matrix[:,0]+matrix[:,1]+matrix[:,2]+matrix[:,3]+matrix[:,10]+0.44*(matrix[:,4]+matrix[:,5])+matrix[:,8])\n",
    "    # Effective Field Goal Percentage\n",
    "    eFG = (matrix[:,0]+matrix[:,2]+0.5*matrix[:,2])/(matrix[:,0]+matrix[:,1]+matrix[:,2]+matrix[:,3])\n",
    "    return possessions, OER, DER, ASTr, OReb, DReb, TOV, eFG*100, lineups, possessionsVal, teams\n",
    "\n",
    "# Obtain advanced stats \n",
    "possessions, OER, DER, ASTr, OReb, DReb, TOV, eFG, lineups, possessionsVal, teams = basic2advancedStats(basicStatsOf, allLineups, basicStatsDef, minPoss,allTeams)\n",
    "NET = OER-DER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have: lineup combinations, and individual feature vectors. Hence, the next step is to find the feature vectors corresponding to each player in every combination, and concatenate them to have a single feature vector / combo. However, there's one main limitation: individual feature vectors include season data, while combinations just add together all seasons in one; in these scenarios, which are not repeated a lot (apart from Spanoulis-Printezis combos et al.), we'll pick a random season of the given sample. At the same time, apart from storing features from players, we are also gathering the performance of the lineup in terms of the advanced statistic to be predicted (OER in the default example). \n",
    "\n",
    "Finally, another aspect to be remarked is that once we have one feature vector per player, when concatenating, we'll sort the vector by their \"offensive load\" value. In this way, we'll always have the \"most important offensive player\" in the first 10 positions of the array, the second one in the positions from 10 to 20, and so on; it makes sense to concatenate vector by using a non-random pattern, in order to make better predictions a posteriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define year range\n",
    "yearBeg = 2007\n",
    "yearFin = 2019\n",
    "\n",
    "# Decide which sample is gonna be regressed (could be any advanced stat from the previous ones)\n",
    "statSample = np.copy(OER)\n",
    "statString = 'OER'\n",
    "\n",
    "# Initialize and build feature vectors\n",
    "featVecs = []\n",
    "finStat = []\n",
    "finLineups = []\n",
    "for iL in range(0, len(lineups)):\n",
    "    # For each combo, we are gonna check which years did those players play together in one same team\n",
    "    allP = []\n",
    "    for iP in range(0, len(lineups[iL])):\n",
    "        allPi = []\n",
    "        for iYear in range(yearBeg, yearFin):\n",
    "            # Search with Player Name + Season + Current Team\n",
    "            strName = lineups[iL][iP] + ' ' + str(iYear) + ' ' + teams[iL]\n",
    "            if strName in matNames:\n",
    "                # If the player exists, append index, otherwise -1\n",
    "                allPi.append(matNames.index(lineups[iL][iP] + ' ' + str(iYear) + ' ' + teams[iL]))\n",
    "            else:\n",
    "                allPi.append(-1)\n",
    "        allP.append(allPi)\n",
    "    allP = np.array(allP)\n",
    "    \n",
    "    # Check which possible years can be chosen (generally < 2)\n",
    "    yearPoss = []\n",
    "    try:\n",
    "        for iYear in range(0, yearFin-yearBeg):\n",
    "            # For each year, check if all players in a lineup played\n",
    "            if np.sum(allP[:,iYear] > -1) == nPlayers:\n",
    "                yearPoss.append(iYear)\n",
    "        # Chose one of the random options and store the corresponding year\n",
    "        finYear = random.choice(yearPoss)\n",
    "        \n",
    "        # Declare feature vector\n",
    "        concVecs = []\n",
    "        for iP in range(0, len(lineups[iL])):\n",
    "            # Find the feature vector that belongs to each player plus season\n",
    "            strName = lineups[iL][iP] + ' ' + str(finYear+yearBeg) + ' ' + teams[iL]\n",
    "            concVecs.append(featVecsInd[matNames.index(strName)])\n",
    "        # Sort vectors by offensive load\n",
    "        posSort = np.argsort(np.array(concVecs)[:,1])\n",
    "        posSort = posSort[::-1]\n",
    "        # Final lineup feature vector containing all players\n",
    "        featVecsi = np.zeros(nPlayers*nFeats,)\n",
    "        for iP in range(0, len(posSort)):\n",
    "            featVecsi[iP*nFeats:(iP+1)*nFeats] = concVecs[posSort[iP]]\n",
    "        # Append all feature vectors - final stat to be regressed - lineups\n",
    "        featVecs.append(np.array(featVecsi).flatten())\n",
    "        finStat.append(statSample[iL])\n",
    "        finLineups.append(lineups[iL])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model - Training\n",
    "It's been a long ride, but once we got a single feature vector / lineup and an associated value (stat) for each lineup, we are able to train our model. Before getting started though, we'll do, once again the train-test split once shuffled the dataset. Note that we also store each lineup name in a single string for a better printing of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Shuffler\n",
    "posAux = np.arange(len(featVecs))\n",
    "np.random.shuffle(posAux)\n",
    "\n",
    "# Shuffle dataset\n",
    "featVecs = np.array(featVecs)[posAux]\n",
    "finStat = np.array(finStat)[posAux]\n",
    "finLineups = np.array(finLineups)[posAux]\n",
    "\n",
    "# Split into train and test\n",
    "partTrain = 0.8\n",
    "posTrain = int(len(featVecs)*partTrain)\n",
    "# Training Set\n",
    "featVecs_train = featVecs[:posTrain]\n",
    "namesTrain = finLineups[:posTrain]\n",
    "statSample_train = finStat[:posTrain]\n",
    "# Test Set\n",
    "featVecs_test = featVecs[posTrain+1:]\n",
    "namesTestAux = finLineups[posTrain+1:]\n",
    "statSample_test = finStat[posTrain+1:]\n",
    "# Convert lineup combinations in single concatenated strings\n",
    "namesTest = []\n",
    "for iName in range(0, len(namesTestAux)):\n",
    "    nameAux = ''\n",
    "    for iP in range(0, nPlayers):\n",
    "        nameAux = nameAux + str(namesTestAux[iName][iP].split(',')[0]) + ' '\n",
    "    nameAux = nameAux[:-1]\n",
    "    namesTest.append(nameAux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As happened with the case of Classification, the library Scikit-Learn has several options when it comes to predictive linear models (https://scikit-learn.org/stable/modules/linear_model.html); in the given example, we train by using a Linear Regression model, but please note that this is not the only option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model \n",
    "regr = linear_model.LinearRegression()\n",
    "## Other possibilities\n",
    "#regr = linear_model.LassoLars()\n",
    "#regr = linear_model.SGDRegressor()\n",
    "#regr = svm.SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model - Testing\n",
    "Once trained, we will use the testing samples to assess the performance of the model. Normally, the coefficients of the model are analyzed together with the computation of MSE, but since we are strictly talking about basketball, we can also use metrics such as Mean Absolute Error or Median Absolute Error, that will express the results in \"basketball language\" units (same statistic we are predicting -- points/100 possessions, assists, rebounds...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat OER\n",
      "Mean Absolute Error: 5.49\n",
      "Median Absolute Error: 4.24\n"
     ]
    }
   ],
   "source": [
    "# Train Model \n",
    "regr.fit(featVecs_train, statSample_train)\n",
    "## In case you want to save the trained model\n",
    "#pickle.dump(regr, open(sFolder + 'Models/' + statString + str(nPlayers) + '.pkl', 'wb'))\n",
    "\n",
    "# Test Model\n",
    "Stat_pred = regr.predict(featVecs_test)\n",
    "\n",
    "## In case you want to inspect the obtained results, building a Pandas Dataframe might be useful\n",
    "#matPred = [Stat_pred,statSample_test]\n",
    "#columnsT = ['Predicted ' + statString,'Real ' + statString]\n",
    "#matPredDF = pd.DataFrame(np.transpose(np.array(matPred)), index=namesTest, columns=columnsT)\n",
    "\n",
    "print('Stat ' + str(statString))\n",
    "print('Mean Absolute Error: %.2f' % np.mean(np.abs(statSample_test-Stat_pred)))\n",
    "print('Median Absolute Error: %.2f' % np.median(np.abs(statSample_test-Stat_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having accuracy metrics is always nice, but... Once we know that the model is somewhat reliable, wouldn't it be much more cool to have a plug&play tool that predicts the performance of any given lineup? Ofc! \n",
    "In the following snippet of code, you can introduce the players you want to (name + year), and the model will do the rest for you. In some cases, you'll see that certain players might not be found; that might be due to a shooting threshold: in order to appear in the individual feature-vector dataset, the player must have attempted, at least, 100 shots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted OER: 127.33999457749003\n"
     ]
    }
   ],
   "source": [
    "# For an empty group of players\n",
    "featVecs_choice = []\n",
    "# Avoid seasons\n",
    "matNames_noT = [x[:-4] for x in matNames]\n",
    "\n",
    "# Fill feature vectors with the desired players\n",
    "for i in range(0, nPlayers):\n",
    "    if i == 0:\n",
    "        name = 'RODRIGUEZ, SERGIO'\n",
    "        year = '2015'\n",
    "    elif i == 1:\n",
    "        name = 'NAVARRO, JUAN CARLOS'\n",
    "        year = '2010'\n",
    "    elif i == 2:\n",
    "        name = 'SINGLETON, CHRIS'\n",
    "        year = '2016'\n",
    "    elif i == 3: \n",
    "        name = 'KAUN, SASHA'\n",
    "        year = '2013'\n",
    "    elif i == 4:\n",
    "        name = 'DATOME, LUIGI'\n",
    "        year = '2016'\n",
    "    featVecs_choice.append(featVecsInd[matNames_noT.index(name.upper() + ' ' + year)])\n",
    "# Reshape\n",
    "featVecs_choice = np.reshape(np.array(featVecs_choice),(1,nPlayers*nFeats))\n",
    "# Predict lineup performance\n",
    "pred_out = regr.predict(featVecs_choice)\n",
    "print('Predicted ' + statString + ': ' + str(pred_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineup Similarity \n",
    "\n",
    "Finally, another cool application would be the comparison with other similar lineups. By checking all possible combinations and by computing the absolute difference between lineups, the final results can be sorted in terms of similarity while displaying the predicted stats too; in this way, the user can also see the performance of similar lineups. A deep dive regarding this topic can be found in Todd Whitehead's talk in \"Beyond the 4 Factors\": https://www.youtube.com/watch?v=DKv-1n5OHEc&ab_channel=Adri%C3%A0Arbu%C3%A9s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Lineups\n",
      "1. MELLI SLOUKAS VESELY WANAMAKER OER: 129.04655685197898\n",
      "2. DE COLO HINES KURBANOV TEODOSIC OER: 148.40606029602347\n",
      "3. LORBEK MICKEAL NAVARRO VAZQUEZ OER: 119.37836429935753\n",
      "4. DAVIES MICIC PANGOS ULANOVAS OER: 120.59345014601584\n",
      "5. DUNSTON LARKIN MICIC MOERMAN OER: 130.42391004415012\n",
      "6. HIGGINS HINES KURBANOV TEODOSIC OER: 126.30319908597545\n",
      "7. DE COLO KAUN TEODOSIC VORONTSEVICH OER: 123.74865361464869\n",
      "8. DE COLO HINES JACKSON KURBANOV OER: 134.41713205844192\n",
      "9. CLYBURN DE COLO HUNTER RODRIGUEZ OER: 131.0383606853836\n",
      "10. CLYBURN DE COLO HINES RODRIGUEZ OER: 135.2153685991281\n"
     ]
    }
   ],
   "source": [
    "# Initialize vector of differences\n",
    "diffTot = []\n",
    "finLineups_flat = []\n",
    "# Find all sorting combinations of players\n",
    "if nPlayers == 2:\n",
    "    pPerm = list(itertools.permutations([0, 1]))\n",
    "elif nPlayers == 3:\n",
    "    pPerm = list(itertools.permutations([0, 1, 2]))\n",
    "elif nPlayers == 4:\n",
    "    pPerm = list(itertools.permutations([0, 1, 2, 3]))\n",
    "elif nPlayers == 5:\n",
    "    pPerm = list(itertools.permutations([0, 1, 2, 3, 4]))\n",
    "\n",
    "for iLin in range(0, len(finLineups)):\n",
    "    difPermi = []\n",
    "    # Find the absolute difference between lineups for all possible combinations\n",
    "    for perm in range(0, len(pPerm)):\n",
    "        featPerm = np.zeros((1,nPlayers*nFeats))\n",
    "        for iP in range(0, len(pPerm[perm])):\n",
    "            featPerm[0,iP*nFeats:(iP+1)*nFeats] = featVecs[iLin][pPerm[perm][iP]*nFeats:(pPerm[perm][iP]+1)*nFeats]\n",
    "        difPermi.append(np.sum(np.abs(featPerm-featVecs_choice)))\n",
    "    # Take the minimum difference\n",
    "    diffTot.append(min(difPermi))\n",
    "\n",
    "    # Get a single string/lineup\n",
    "    nameAux = ''\n",
    "    for iP in range(0, nPlayers):\n",
    "        nameAux = nameAux + str(finLineups[iLin][iP].split(',')[0]) + ' '\n",
    "    nameAux = nameAux[:-1]\n",
    "    finLineups_flat.append(nameAux)\n",
    "\n",
    "# Sort lineups, from minimum to maximum difference\n",
    "diffTot_top, finStat_top, finLineups_top, diffTot = zip(*sorted(zip(np.array(diffTot), finStat, np.array(finLineups_flat), np.array(diffTot))))\n",
    "sumDiffs = np.sum(featVecs_choice)\n",
    "\n",
    "# Print the iSim first similar lineups\n",
    "iSim = 10\n",
    "print('Top ' + str(iSim) + ' Lineups')\n",
    "for iS in range(0, iSim):\n",
    "    print(str(iS+1) + '. ' +  finLineups_top[iS] + ' ' + statString + ': ' + str(finStat_top[iS]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you liked it! \n",
    "If you have any questions / suggestions, feel free to send me an email (adria.arbues@upf.edu) or a Twitter DM (@arbues6). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
